-module(topos_lexer_properties).
-include_lib("proper/include/proper.hrl").
-include_lib("eunit/include/eunit.hrl").

%%====================================================================
%% PropEr Property-Based Fuzzing Tests for Topos Lexer
%%====================================================================

%%====================================================================
%% Test Entry Point
%%====================================================================

proper_test_() ->
    {timeout, 300, fun() ->
        ?assertEqual([], proper:module(?MODULE, [{numtests, 100}, {max_size, 20}]))
    end}.

%%====================================================================
%% Generators
%%====================================================================

%% Valid identifier characters
lower_alpha() -> oneof(lists:seq($a, $z)).
upper_alpha() -> oneof(lists:seq($A, $Z)).
digit() -> oneof(lists:seq($0, $9)).
underscore() -> $_.

%% Generate valid lower identifiers
valid_lower_ident() ->
    ?LET({First, Rest}, {lower_alpha(), list(oneof([lower_alpha(), upper_alpha(), digit(), underscore()]))},
         [First | Rest]).

%% Generate valid upper identifiers
valid_upper_ident() ->
    ?LET({First, Rest}, {upper_alpha(), list(oneof([lower_alpha(), upper_alpha(), digit(), underscore()]))},
         [First | Rest]).

%% Generate valid escape sequences
valid_escape() ->
    oneof(["\\n", "\\r", "\\t", "\\\\", "\\\"", "\\'"]).

%% Generate invalid escape sequences (security-critical)
invalid_escape() ->
    oneof([
        "\\x00", "\\x41", "\\xFF",  % Hex escapes
        "\\0", "\\1", "\\7",         % Octal escapes
        "\\u0041", "\\uFFFF",        % Unicode escapes
        "\\a", "\\b", "\\f", "\\v", "\\e"  % Other escapes
    ]).

%% Generate safe string content (no quotes, no backslashes)
safe_string_char() ->
    ?SUCHTHAT(C, oneof(lists:seq(32, 126)), C =/= $" andalso C =/= $\\).

%% Generate valid string content
valid_string_content() ->
    list(oneof([safe_string_char(), valid_escape()])).

%% Generate integers
valid_integer() ->
    ?LET(N, nat(), integer_to_list(N)).

%% Generate floats
valid_float() ->
    ?LET({I, F}, {nat(), nat()},
         integer_to_list(I) ++ "." ++ integer_to_list(F)).

%% Generate keywords
keyword() ->
    oneof([
        "shape", "flow", "match", "where", "let", "in", "do", "end",
        "if", "then", "else", "case", "of", "when",
        "trait", "instance", "extends", "forall",
        "effect", "operation", "perform", "try", "with"
    ]).

%%====================================================================
%% Properties: Valid Inputs
%%====================================================================

%% Property: Valid lower identifiers always tokenize
prop_valid_lower_ident() ->
    ?FORALL(Ident, valid_lower_ident(),
        begin
            {ok, Tokens, _} = topos_lexer:string(Ident),
            length(Tokens) =:= 1 andalso
            element(1, hd(Tokens)) =:= lower_ident
        end).

%% Property: Valid upper identifiers always tokenize
prop_valid_upper_ident() ->
    ?FORALL(Ident, valid_upper_ident(),
        begin
            {ok, Tokens, _} = topos_lexer:string(Ident),
            length(Tokens) =:= 1 andalso
            element(1, hd(Tokens)) =:= upper_ident
        end).

%% Property: Valid integers always parse correctly
prop_valid_integer() ->
    ?FORALL(IntStr, valid_integer(),
        begin
            Expected = list_to_integer(IntStr),
            {ok, Tokens, _} = topos_lexer:string(IntStr),
            case Tokens of
                [{integer, _, Value}] -> Value =:= Expected;
                _ -> false
            end
        end).

%% Property: Valid floats always parse correctly
prop_valid_float() ->
    ?FORALL(FloatStr, valid_float(),
        begin
            case catch list_to_float(FloatStr) of
                {'EXIT', _} -> true;  % Skip invalid floats
                Expected ->
                    {ok, Tokens, _} = topos_lexer:string(FloatStr),
                    case Tokens of
                        [{float, _, Value}] -> abs(Value - Expected) < 0.0001;
                        _ -> false
                    end
            end
        end).

%% Property: Valid strings with escapes always tokenize
prop_valid_string_with_escapes() ->
    ?FORALL(Content, valid_string_content(),
        begin
            Source = "\"" ++ lists:flatten(Content) ++ "\"",
            case topos_lexer:string(Source) of
                {ok, [{string, _, _}], _} -> true;
                _ -> false
            end
        end).

%% Property: Keywords are always recognized
prop_keywords_recognized() ->
    ?FORALL(KW, keyword(),
        begin
            {ok, Tokens, _} = topos_lexer:string(KW),
            length(Tokens) =:= 1 andalso
            is_tuple(hd(Tokens)) andalso
            element(1, hd(Tokens)) =:= list_to_atom(KW)
        end).

%%====================================================================
%% Properties: Security - Invalid Escapes
%%====================================================================

%% Property: Invalid escape sequences are always rejected (SECURITY)
prop_invalid_escapes_rejected() ->
    ?FORALL(Escape, invalid_escape(),
        begin
            Source = "\"test" ++ Escape ++ "end\"",
            case topos_lexer:string(Source) of
                {error, _, _} -> true;  % Correctly rejected
                {ok, _, _} -> false     % SECURITY BUG!
            end
        end).

%% Property: Null bytes in hex form are rejected (SECURITY)
prop_null_byte_injection_blocked() ->
    ?FORALL(Context, list(safe_string_char()),
        begin
            Source = "\"" ++ Context ++ "\\x00" ++ Context ++ "\"",
            case topos_lexer:string(Source) of
                {error, _, _} -> true;  % Blocked
                {ok, _, _} -> false     % SECURITY BUG!
            end
        end).

%% Property: Command injection via escapes is blocked (SECURITY)
prop_command_injection_blocked() ->
    ?FORALL(Cmd, list(safe_string_char()),
        begin
            Injections = ["\\x0a", "\\x0d", "\\x0a\\x0d"],
            lists:all(fun(Inj) ->
                Source = "\"" ++ Cmd ++ Inj ++ "; rm -rf /\"",
                case topos_lexer:string(Source) of
                    {error, _, _} -> true;
                    {ok, _, _} -> false
                end
            end, Injections)
        end).

%%====================================================================
%% Properties: Robustness
%%====================================================================

%% Property: Lexer never crashes on any input
prop_lexer_never_crashes() ->
    ?FORALL(Input, list(oneof(lists:seq(0, 255))),
        begin
            case catch topos_lexer:string(Input) of
                {'EXIT', _} -> false;  % Crash!
                {ok, _, _} -> true;
                {error, _, _} -> true
            end
        end).

%% Property: Empty string always tokenizes to empty list
prop_empty_string() ->
    begin
        {ok, Tokens, _} = topos_lexer:string(""),
        Tokens =:= []
    end.

%% Property: Whitespace is always ignored
prop_whitespace_ignored() ->
    ?FORALL(WS, list(oneof([$\s, $\t, $\n, $\r])),
        begin
            {ok, Tokens, _} = topos_lexer:string(WS),
            Tokens =:= []
        end).

%%====================================================================
%% Properties: Identifier Constraints
%%====================================================================

%% Property: Identifiers have length limits
prop_identifier_length_limits() ->
    ?FORALL(Length, choose(1, 300),
        begin
            Ident = lists:duplicate(Length, $a),
            case topos_lexer:string(Ident) of
                {ok, [{lower_ident, _, _}], _} when Length =< 255 -> true;
                {error, {identifier_too_long, _, _, _}} when Length > 255 -> true;
                _ -> false
            end
        end).

%%====================================================================
%% Properties: Numeric Literals
%%====================================================================

%% Property: Scientific notation always parses
prop_scientific_notation() ->
    ?FORALL({Base, Exp}, {choose(1, 1000), choose(-10, 10)},
        begin
            Source = integer_to_list(Base) ++ "e" ++ integer_to_list(Exp),
            case topos_lexer:string(Source) of
                {ok, [{float, _, _}], _} -> true;
                _ -> false
            end
        end).

%% Property: Leading zeros in integers are accepted
prop_leading_zeros() ->
    ?FORALL(Zeros, choose(1, 10),
        begin
            Source = lists:duplicate(Zeros, $0) ++ "123",
            case topos_lexer:string(Source) of
                {ok, [{integer, _, _}], _} -> true;
                _ -> false
            end
        end).

%%====================================================================
%% Properties: String Literals
%%====================================================================

%% Property: Empty strings always work
prop_empty_string_literal() ->
    begin
        {ok, [{string, _, Value}], _} = topos_lexer:string("\"\""),
        Value =:= ""
    end.

%% Property: Strings can contain any safe character
prop_safe_characters_in_strings() ->
    ?FORALL(Chars, list(safe_string_char()),
        begin
            Source = "\"" ++ Chars ++ "\"",
            case topos_lexer:string(Source) of
                {ok, [{string, _, Value}], _} -> Value =:= Chars;
                _ -> false
            end
        end).

%% Property: Multiple valid escapes in one string
prop_multiple_escapes() ->
    ?FORALL(Escapes, list(valid_escape()),
        begin
            Content = lists:flatten(Escapes),
            Source = "\"" ++ Content ++ "\"",
            case topos_lexer:string(Source) of
                {ok, [{string, _, _}], _} -> true;
                _ -> false
            end
        end).

%% Property: String length limits are enforced
prop_string_length_limits() ->
    ?FORALL(Length, choose(1, 10000),
        begin
            %% Max is 8192 (including quotes), so content max is 8190
            Content = lists:duplicate(Length, $a),
            Source = "\"" ++ Content ++ "\"",
            case topos_lexer:string(Source) of
                {ok, [{string, _, _}], _} when Length =< 8190 -> true;
                {error, {_, topos_lexer, {user, {string_too_long, _, _, _}}}, _} when Length > 8190 -> true;
                _ -> false
            end
        end).

%%====================================================================
%% Properties: Comment Depth Limits
%%====================================================================

%% Property: Comment depth limits are enforced
prop_comment_depth_limits() ->
    ?FORALL(Depth, choose(1, 150),
        begin
            %% Max depth is 100
            Opening = lists:flatten(lists:duplicate(Depth, "{- ")),
            Closing = lists:flatten(lists:duplicate(Depth, " -}")),
            Source = "x " ++ Opening ++ "nested" ++ Closing ++ " y",
            case topos_lexer:tokenize(Source) of
                {ok, [{lower_ident, _, "x"}, {lower_ident, _, "y"}]} when Depth =< 100 -> true;
                {error, {_, topos_lexer, {comment_depth_exceeded, _, _}}} when Depth > 100 -> true;
                _ -> false
            end
        end).

%%====================================================================
%% Properties: Comments
%%====================================================================

%% Property: Comments are always ignored
prop_comments_ignored() ->
    ?FORALL(Comment, list(safe_string_char()),
        begin
            Source = "-- " ++ Comment,
            {ok, Tokens, _} = topos_lexer:string(Source),
            Tokens =:= []
        end).

%% Property: Comments at end of line don't affect tokens
prop_comments_end_of_line() ->
    ?FORALL(Comment, list(safe_string_char()),
        begin
            Source = "hello -- " ++ Comment,
            {ok, Tokens, _} = topos_lexer:string(Source),
            length(Tokens) =:= 1 andalso
            element(1, hd(Tokens)) =:= lower_ident
        end).

%%====================================================================
%% Properties: Operators
%%====================================================================

%% Property: All operators tokenize correctly
prop_operators() ->
    Operators = [
        {"|>", pipe_right},
        {"->", arrow},
        {"=>", double_arrow},
        {"===", setoid_eq},
        {"!==", setoid_neq},
        {"==", eq},
        {"/=", neq},
        {"<=", lte},
        {">=", gte},
        {"<", lt},
        {">", gt},
        {"::", cons},
        {"<-", left_arrow},
        {"..", range},
        {":", colon},
        {"=", equals},
        {"|", pipe},
        {"+", plus},
        {"-", minus},
        {"*", star},
        {"/", slash},
        {".", dot}
    ],
    lists:all(fun({Op, Expected}) ->
        {ok, Tokens, _} = topos_lexer:string(Op),
        case Tokens of
            [{Expected, _}] -> true;
            _ -> false
        end
    end, Operators).

%%====================================================================
%% Properties: Delimiters
%%====================================================================

%% Property: All delimiters tokenize correctly
prop_delimiters() ->
    Delimiters = [
        {"{", lbrace},
        {"}", rbrace},
        {"[", lbracket},
        {"]", rbracket},
        {"(", lparen},
        {")", rparen},
        {",", comma},
        {";", semicolon},
        {"_", underscore}
    ],
    lists:all(fun({Delim, Expected}) ->
        {ok, Tokens, _} = topos_lexer:string(Delim),
        case Tokens of
            [{Expected, _}] -> true;
            _ -> false
        end
    end, Delimiters).

%%====================================================================
%% Properties: Combined Inputs
%%====================================================================

%% Property: Multiple tokens in sequence
prop_multiple_tokens() ->
    ?FORALL({Id1, Id2}, {valid_lower_ident(), valid_lower_ident()},
        begin
            Source = Id1 ++ " " ++ Id2,
            case topos_lexer:string(Source) of
                {ok, Tokens, _} -> length(Tokens) =:= 2;
                _ -> false
            end
        end).

%% Property: Token boundaries are respected
prop_token_boundaries() ->
    begin
        % "shapeshape" should be one identifier, not two "shape" keywords
        {ok, Tokens, _} = topos_lexer:string("shapeshape"),
        case Tokens of
            [{lower_ident, _, "shapeshape"}] -> true;
            _ -> false
        end
    end.

%%====================================================================
%% Properties: UTF-8 and Unicode Validation (Security)
%%====================================================================

%% Property: Valid Unicode code points always accepted (SECURITY)
prop_valid_unicode_codepoints() ->
    ?FORALL(Codepoint, oneof([
        choose(0, 16#D7FF),              % BMP (excluding surrogates)
        choose(16#E000, 16#FFFF),        % BMP Private Use
        choose(16#10000, 16#10FFFF)      % Supplementary Planes
    ]),
        begin
            Source = [34, Codepoint, 34],  % Wrap in quotes for string literal
            case topos_lexer:tokenize(Source) of
                {ok, [{string, _, _}]} -> true;
                _ -> false
            end
        end).

%% Property: Surrogate code points always rejected (SECURITY)
prop_surrogate_codepoints_rejected() ->
    ?FORALL(Surrogate, choose(16#D800, 16#DFFF),
        begin
            Source = [Surrogate],
            case topos_lexer:tokenize(Source) of
                {error, {0, topos_lexer, {invalid_unicode, 1, Surrogate, _}}} -> true;
                _ -> false
            end
        end).

%% Property: Code points beyond Unicode range rejected (SECURITY)
prop_beyond_unicode_rejected() ->
    ?FORALL(Invalid, choose(16#110000, 16#1FFFFF),
        begin
            Source = [Invalid],
            case topos_lexer:tokenize(Source) of
                {error, {0, topos_lexer, {invalid_unicode, 1, Invalid, _}}} -> true;
                _ -> false
            end
        end).

%% Property: Negative code points rejected (SECURITY)
prop_negative_codepoints_rejected() ->
    ?FORALL(Negative, choose(-1000, -1),
        begin
            Source = [Negative],
            case topos_lexer:tokenize(Source) of
                {error, {0, topos_lexer, {invalid_unicode, 1, Negative, _}}} -> true;
                _ -> false
            end
        end).

%% Property: Invalid UTF-8 binaries rejected (SECURITY)
prop_invalid_utf8_rejected() ->
    ?FORALL(InvalidByte, oneof([
        <<16#C0, 16#AF>>,              % Overlong encoding (security issue!)
        <<16#C3>>,                      % Incomplete 2-byte sequence
        <<16#E0, 16#80>>,               % Incomplete 3-byte sequence
        <<16#F0, 16#80, 16#80>>,        % Incomplete 4-byte sequence
        <<16#80>>,                      % Standalone continuation byte
        <<16#FE>>,                      % Invalid start byte
        <<16#FF>>                       % Invalid start byte
    ]),
        begin
            case topos_lexer:tokenize(InvalidByte) of
                {error, {0, topos_lexer, {invalid_utf8, _}}} -> true;
                _ -> false
            end
        end).

%% Property: Valid UTF-8 binaries with valid tokens always accepted
prop_valid_utf8_accepted() ->
    ?FORALL(Text, oneof([
        valid_lower_ident(),
        valid_upper_ident(),
        valid_integer(),
        keyword()
    ]),
        begin
            Binary = list_to_binary(Text),
            case topos_lexer:tokenize(Binary) of
                {ok, _} -> true;
                {error, _} -> false
            end
        end).

%% Property: Mixed valid Unicode in strings works
prop_unicode_in_strings() ->
    ?FORALL(Codepoints, list(oneof([
        choose(32, 126),                 % ASCII printable (excluding quotes/backslash)
        choose(16#A0, 16#D7FF),          % Latin-1 Supplement + others
        choose(16#E000, 16#FFFD),        % Private Use + others
        choose(16#10000, 16#1F6FF)       % Supplementary (including emoji)
    ])),
        begin
            % Filter out quotes and backslashes
            SafePoints = [C || C <- Codepoints, C =/= 34, C =/= 92],
            case SafePoints of
                [] -> true;  % Empty is valid
                _ ->
                    Source = [34] ++ SafePoints ++ [34],  % Wrap in quotes
                    case topos_lexer:tokenize(Source) of
                        {ok, [{string, _, _}]} -> true;
                        _ -> false
                    end
            end
        end).
