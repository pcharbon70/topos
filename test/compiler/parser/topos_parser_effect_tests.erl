-module(topos_parser_effect_tests).
-include_lib("eunit/include/eunit.hrl").

%% Import shared test utilities to eliminate duplication
%% This eliminates the duplicate helper functions that were previously defined
%% in this module and now uses the centralized test_helpers module.
-import(test_helpers, [
    tokenize_source/1,
    parse_and_expect_error/1,
    parse_and_expect_success/1,
    assert_error_has_location/1,
    create_nested_try_with/2
]).

%% NOTE: This module used to have duplicate helper functions:
%% - tokenize/1 (now uses test_helpers:tokenize_source/1)
%% - parse_and_expect_error/1 (now uses test_helpers:parse_and_expect_error/1)
%% - assert_error_has_location/1 (now uses test_helpers:assert_error_has_location/1)
%% - create_nested_try_with/2 (now uses test_helpers:create_nested_try_with/2)
%%
%% All duplicated code has been removed and centralized in test_helpers.erl

%%====================================================================
%% Effect Declaration Tests
%%====================================================================

effect_decl_empty_test() ->
    %% Test empty effect declaration
    Code = "effect FileIO end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {effect_decl, 'FileIO', [], _}
        ], _},
        AST
    ).

effect_decl_empty_with_whitespace_test() ->
    %% Test empty effect declaration with internal whitespace formatting
    Code = "effect PureEffect \n\nend",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {effect_decl, 'PureEffect', [], _}
        ], _},
        AST
    ).

%%====================================================================
%% Empty Effect Annotation Tests
%%====================================================================
% TODO: Add support for empty effect annotations in flow type signatures.
% These tests document the desired behavior for pure functions.

%% Test pure function with empty effect annotation (desired behavior)
effect_annotation_empty_desired_test() ->
    %% This test documents the desired behavior: pure functions with {}
    %% TODO: Update parser grammar to support empty effect annotations
    Code = "flow pureAdd : Int / {}",
    Result = parse_and_expect_error(Code),
    io:format("Empty effect annotation gap: ~p~n", [Result]),
    ?assertMatch({error, _}, Result).  % Current behavior - should be fixed

%% Test pure function with empty effect annotation and whitespace (desired behavior)
effect_annotation_empty_with_whitespace_desired_test() ->
    %% This test documents the desired behavior with formatting
    %% TODO: Update parser grammar to support empty effect annotations
    Code = "flow pureFunc : String / { }",
    Result = parse_and_expect_error(Code),
    io:format("Empty effect annotation with whitespace gap: ~p~n", [Result]),
    ?assertMatch({error, _}, Result).  % Current behavior - should be fixed

%%====================================================================
%% Effect Resource Limits Tests
%%====================================================================
%%
%% Tests for effect-specific resource limits and protection mechanisms.
%% Ensures the parser enforces reasonable bounds on effect constructs
%% to prevent resource exhaustion and DOS attacks.
%%
%% These tests verify:
%% 1. Effect declaration count limits per module
%% 2. Operation count limits per effect
%% 3. Effect identifier length limits
%% 4. Effect annotation size limits
%% 5. Proper error messages for limit violations

%% Test effect declaration count limit
effect_limits_declarations_test() ->
    %% Set a low limit for testing
    OldMaxEffects = application:get_env(topos, max_effects_per_module, undefined),
    try
        application:set_env(topos, max_effects_per_module, 2),
        
        %% Create module with 3 effects (exceeds limit of 2)
        Code = "effect Effect1\n  operation op1\nend\n"
               "effect Effect2\n  operation op2\nend\n"
               "effect Effect3\n  operation op3\nend",
        Result = parse_and_expect_error(Code),
        ?assertMatch({error, {too_many_effects, 3, 2}}, Result),
        
        %% Verify error message formatting
        ErrorMsg = topos_parse:format_error(element(2, Result)),
        ?assert(is_list(ErrorMsg)),
        ?assert(string:str(ErrorMsg, "too many effect declarations") > 0),
        ?assert(string:str(ErrorMsg, "3") > 0),
        ?assert(string:str(ErrorMsg, "2") > 0)
    after
        case OldMaxEffects of
            undefined -> application:unset_env(topos, max_effects_per_module);
            Value -> application:set_env(topos, max_effects_per_module, Value)
        end
    end.

%% Test operation count limit per effect
effect_limits_operations_per_effect_test() ->
    %% Set a low limit for testing
    OldMaxOps = application:get_env(topos, max_operations_per_effect, undefined),
    try
        application:set_env(topos, max_operations_per_effect, 3),
        
        %% Create effect with 5 operations (exceeds limit of 3)
        Code = "effect BusyEffect\n"
               "  operation op1 : String\n"
               "  operation op2 : Int\n"
               "  operation op3 : Bool\n"
               "  operation op4 : Unit\n"
               "  operation op5\n"
               "end",
        Result = parse_and_expect_error(Code),
        ?assertMatch({error, {too_many_operations, 'BusyEffect', 5, 3}}, Result),
        
        %% Verify error message formatting
        ErrorMsg = topos_parse:format_error(element(2, Result)),
        ?assert(is_list(ErrorMsg)),
        ?assert(string:str(ErrorMsg, "too many operations") > 0),
        ?assert(string:str(ErrorMsg, "BusyEffect") > 0),
        ?assert(string:str(ErrorMsg, "5") > 0),
        ?assert(string:str(ErrorMsg, "3") > 0)
    after
        case OldMaxOps of
            undefined -> application:unset_env(topos, max_operations_per_effect);
            Value -> application:set_env(topos, max_operations_per_effect, Value)
        end
    end.

%% Test effect name length limit
effect_limits_effect_name_length_test() ->
    %% Set a low limit for testing
    OldMaxIdLength = application:get_env(topos, max_effect_identifier_length, undefined),
    try
        application:set_env(topos, max_effect_identifier_length, 10),
        
        %% Create effect with name 15 characters long (exceeds limit of 10)
        LongEffectName = "VeryLongEffectName",
        Code = "effect " ++ LongEffectName ++ "\n"
               "  operation test\n"
               "end",
        Result = parse_and_expect_error(Code),
        ?assertMatch({error, {effect_name_too_long, _, 15, 10}}, Result),
        
        %% Verify error message formatting
        ErrorMsg = topos_parse:format_error(element(2, Result)),
        ?assert(is_list(ErrorMsg)),
        ?assert(string:str(ErrorMsg, "too long") > 0),
        ?assert(string:str(ErrorMsg, "15") > 0),
        ?assert(string:str(ErrorMsg, "10") > 0)
    after
        case OldMaxIdLength of
            undefined -> application:unset_env(topos, max_effect_identifier_length);
            Value -> application:set_env(topos, max_effect_identifier_length, Value)
        end
    end.

%% Test operation name length limit
effect_limits_operation_name_length_test() ->
    %% Set a low limit for testing
    OldMaxIdLength = application:get_env(topos, max_effect_identifier_length, undefined),
    try
        application:set_env(topos, max_effect_identifier_length, 8),
        
        %% Create operation with name 12 characters long (exceeds limit of 8)
        Code = "effect TestEffect\n"
               "  operation veryLongOperationName : String\n"
               "  operation shortOp\n"
               "end",
        Result = parse_and_expect_error(Code),
        ?assertMatch({error, {operation_name_too_long, _, 12, 8}}, Result),
        
        %% Verify error message formatting
        ErrorMsg = topos_parse:format_error(element(2, Result)),
        ?assert(is_list(ErrorMsg)),
        ?assert(string:str(ErrorMsg, "too long") > 0),
        ?assert(string:str(ErrorMsg, "veryLongOperationName") > 0),
        ?assert(string:str(ErrorMsg, "12") > 0),
        ?assert(string:str(ErrorMsg, "8") > 0)
    after
        case OldMaxIdLength of
            undefined -> application:unset_env(topos, max_effect_identifier_length);
            Value -> application:set_env(topos, max_effect_identifier_length, Value)
        end
    end.

%% Test effect annotation size limit
effect_limits_annotation_size_test() ->
    %% Set a low limit for testing
    OldMaxAnnotation = application:get_env(topos, max_effects_in_annotation, undefined),
    try
        application:set_env(topos, max_effects_in_annotation, 2),
        
        %% Create flow with 3 effects in annotation (exceeds limit of 2)
        Code = "flow heavyComputation : Int / {FileIO, Console, Network}\n"
               "heavyComputation _ = 1",
        Result = parse_and_expect_error(Code),
        ?assertMatch({error, {too_many_effects_in_annotation, 3, 2}}, Result),
        
        %% Verify error message formatting
        ErrorMsg = topos_parse:format_error(element(2, Result)),
        ?assert(is_list(ErrorMsg)),
        ?assert(string:str(ErrorMsg, "too many effects") > 0),
        ?assert(string:str(ErrorMsg, "3") > 0),
        ?assert(string:str(ErrorMsg, "2") > 0)
    after
        case OldMaxAnnotation of
            undefined -> application:unset_env(topos, max_effects_in_annotation);
            Value -> application:set_env(topos, max_effects_in_annotation, Value)
        end
    end.

%% Test valid cases within limits
effect_limits_valid_within_bounds_test() ->
    %% Set reasonable limits
    OldMaxEffects = application:get_env(topos, max_effects_per_module, undefined),
    OldMaxOps = application:get_env(topos, max_operations_per_effect, undefined),
    OldMaxIdLength = application:get_env(topos, max_effect_identifier_length, undefined),
    OldMaxAnnotation = application:get_env(topos, max_effects_in_annotation, undefined),
    try
        application:set_env(topos, max_effects_per_module, 5),
        application:set_env(topos, max_operations_per_effect, 10),
        application:set_env(topos, max_effect_identifier_length, 50),
        application:set_env(topos, max_effects_in_annotation, 5),
        
        %% Create valid code within all limits
        Code = "effect ValidEffect\n"
               "  operation read : String\n"
               "  operation write : String\n"
               "end\n\n"
               "flow validFunc : Int / {ValidEffect}\n"
               "validFunc _ = 42",
        Result = parse_and_expect_success(Code),
        ?assertMatch({module, _, _, _, _, _}, Result)
    after
        case OldMaxEffects of
            undefined -> application:unset_env(topos, max_effects_per_module);
            Value1 -> application:set_env(topos, max_effects_per_module, Value1)
        end,
        case OldMaxOps of
            undefined -> application:unset_env(topos, max_operations_per_effect);
            Value2 -> application:set_env(topos, max_operations_per_effect, Value2)
        end,
        case OldMaxIdLength of
            undefined -> application:unset_env(topos, max_effect_identifier_length);
            Value3 -> application:set_env(topos, max_effect_identifier_length, Value3)
        end,
        case OldMaxAnnotation of
            undefined -> application:unset_env(topos, max_effects_in_annotation);
            Value4 -> application:set_env(topos, max_effects_in_annotation, Value4)
        end
    end.

%% Test limit getters return reasonable defaults
effect_limits_getters_test() ->
    %% Test that all limit getter functions return reasonable values
    ?assert(is_integer(topos_parse:get_max_effects_per_module())),
    ?assert(topos_parse:get_max_effects_per_module() > 0),
    
    ?assert(is_integer(topos_parse:get_max_operations_per_effect())),
    ?assert(topos_parse:get_max_operations_per_effect() > 0),
    
    ?assert(is_integer(topos_parse:get_max_effects_in_annotation())),
    ?assert(topos_parse:get_max_effects_in_annotation() > 0),
    
    ?assert(is_integer(topos_parse:get_max_effect_handler_depth())),
    ?assert(topos_parse:get_max_effect_handler_depth() > 0),
    
    ?assert(is_integer(topos_parse:get_max_effect_identifier_length())),
    ?assert(topos_parse:get_max_effect_identifier_length() > 0).

effect_decl_single_operation_no_type_test() ->
    %% Test effect with single operation without type signature
    Code = "effect Console\n"
           "  operation print\n"
           "end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {effect_decl, 'Console', [
                {effect_operation, print, undefined, _}
            ], _}
        ], _},
        AST
    ).

effect_decl_single_operation_with_type_test() ->
    %% Test effect with single operation with type signature
    Code = "effect FileIO\n"
           "  operation readFile : String\n"
           "end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {effect_decl, 'FileIO', [
                {effect_operation, readFile, {type_con, 'String', _}, _}
            ], _}
        ], _},
        AST
    ).

effect_decl_multiple_operations_test() ->
    %% Test effect with multiple operations
    Code = "effect FileIO\n"
           "  operation readFile : String\n"
           "  operation writeFile : String\n"
           "  operation deleteFile\n"
           "end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {effect_decl, 'FileIO', [
                {effect_operation, readFile, {type_con, 'String', _}, _},
                {effect_operation, writeFile, {type_con, 'String', _}, _},
                {effect_operation, deleteFile, undefined, _}
            ], _}
        ], _},
        AST
    ).

effect_decl_multiple_types_test() ->
    %% Test effect with multiple operations having different simple types
    Code = "effect State\n"
           "  operation get : Unit\n"
           "  operation put : Int\n"
           "end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {effect_decl, 'State', [
                {effect_operation, get, {type_con, 'Unit', _}, _},
                {effect_operation, put, {type_con, 'Int', _}, _}
            ], _}
        ], _},
        AST
    ).

effect_decl_actual_function_type_test() ->
    %% Test effect operation with actual function type (addresses original misleading test)
    %% This tests the real function type syntax that the parser currently supports
    Code = "effect Callback\n"
           "  operation map : (Int->String)\n"
           "  operation process : (String->Int)\n"
           "end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {effect_decl, 'Callback', [
                {effect_operation, map, 
                    {type_fun, {type_con, 'Int', _}, {type_con, 'String', _}, _}, _},
                {effect_operation, process,
                    {type_fun, {type_con, 'String', _}, {type_con, 'Int', _}, _}, _}
            ], _}
        ], _},
        AST
    ).

%%====================================================================
%% Perform Expression Tests
%%====================================================================

perform_expr_no_args_no_parens_test() ->
    %% Test perform expression without arguments (parentheses required in current implementation)
    Code = "flow main = perform Console.print()",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, main, undefined, [
                {flow_clause, [], undefined,
                    {perform_expr, 'Console', print, [], _},
                _}
            ], _}
        ], _},
        AST
    ).

perform_expr_no_args_with_parens_test() ->
    %% Test perform expression with empty parentheses
    Code = "flow main = perform FileIO.readFile()",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, main, undefined, [
                {flow_clause, [], undefined,
                    {perform_expr, 'FileIO', readFile, [], _},
                _}
            ], _}
        ], _},
        AST
    ).

perform_expr_single_arg_test() ->
    %% Test perform expression with single argument
    Code = "flow writeLog msg = perform FileIO.writeFile(msg)",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, writeLog, undefined, [
                {flow_clause, [{pat_var, msg, _}], undefined,
                    {perform_expr, 'FileIO', writeFile, [
                        {var, msg, _}
                    ], _},
                _}
            ], _}
        ], _},
        AST
    ).

perform_expr_multiple_args_test() ->
    %% Test perform expression with multiple arguments
    Code = "flow copyFile src dst = perform FileIO.copy(src, dst)",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, copyFile, undefined, [
                {flow_clause, [{pat_var, src, _}, {pat_var, dst, _}], undefined,
                    {perform_expr, 'FileIO', copy, [
                        {var, src, _},
                        {var, dst, _}
                    ], _},
                _}
            ], _}
        ], _},
        AST
    ).

%%====================================================================
%% Try-With Handler Tests
%%====================================================================

try_with_single_handler_single_operation_test() ->
    %% Test try-with with single handler and single operation
    Code = "flow safe =\n"
           "  try\n"
           "    perform FileIO.readFile()\n"
           "  with FileIO {\n"
           "    readFile -> 42\n"
           "  }\n"
           "  end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, safe, undefined, [
                {flow_clause, [], undefined,
                    {try_with_expr,
                        {perform_expr, 'FileIO', readFile, [], _},
                        [
                            {handler_clause, 'FileIO', [
                                {operation_case, readFile, [],
                                    {literal, 42, integer, _},
                                _}
                            ], _}
                        ],
                    _},
                _}
            ], _}
        ], _},
        AST
    ).

try_with_single_handler_multiple_operations_test() ->
    %% Test try-with with single handler and multiple operations
    Code = "flow safeIO =\n"
           "  try\n"
           "    perform FileIO.readFile()\n"
           "  with FileIO {\n"
           "    readFile -> 0\n"
           "    writeFile -> 1\n"
           "  }\n"
           "  end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, safeIO, undefined, [
                {flow_clause, [], undefined,
                    {try_with_expr,
                        {perform_expr, 'FileIO', readFile, [], _},
                        [
                            {handler_clause, 'FileIO', [
                                {operation_case, readFile, [],
                                    {literal, 0, integer, _},
                                _},
                                {operation_case, writeFile, [],
                                    {literal, 1, integer, _},
                                _}
                            ], _}
                        ],
                    _},
                _}
            ], _}
        ], _},
        AST
    ).

try_with_operation_with_params_test() ->
    %% Test try-with with operation that has parameters
    Code = "flow handleWrite =\n"
           "  try\n"
           "    perform FileIO.writeFile()\n"
           "  with FileIO {\n"
           "    writeFile(path, content) -> path\n"
           "  }\n"
           "  end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, handleWrite, undefined, [
                {flow_clause, [], undefined,
                    {try_with_expr,
                        {perform_expr, 'FileIO', writeFile, [], _},
                        [
                            {handler_clause, 'FileIO', [
                                {operation_case, writeFile, [
                                    {pat_var, path, _},
                                    {pat_var, content, _}
                                ],
                                    {var, path, _},
                                _}
                            ], _}
                        ],
                    _},
                _}
            ], _}
        ], _},
        AST
    ).

try_with_multiple_handlers_test() ->
    %% Test try-with with multiple handlers
    Code = "flow multiEffect =\n"
           "  try\n"
           "    perform FileIO.readFile()\n"
           "  with FileIO {\n"
           "    readFile -> 0\n"
           "  }\n"
           "  Console {\n"
           "    print(msg) -> msg\n"
           "  }\n"
           "  end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, multiEffect, undefined, [
                {flow_clause, [], undefined,
                    {try_with_expr,
                        {perform_expr, 'FileIO', readFile, [], _},
                        [
                            {handler_clause, 'FileIO', [
                                {operation_case, readFile, [],
                                    {literal, 0, integer, _},
                                _}
                            ], _},
                            {handler_clause, 'Console', [
                                {operation_case, print, [
                                    {pat_var, msg, _}
                                ],
                                    {var, msg, _},
                                _}
                            ], _}
                        ],
                    _},
                _}
            ], _}
        ], _},
        AST
    ).

%%====================================================================
%% Effect Annotation Tests
%%====================================================================

effect_annotation_single_effect_test() ->
    %% Test type with single effect annotation
    Code = "flow readConfig : String / {FileIO}",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, readConfig,
                {type_effect,
                    {type_con, 'String', _},
                    ['FileIO'],
                _},
            [], _}
        ], _},
        AST
    ).

effect_annotation_multiple_effects_test() ->
    %% Test type with multiple effect annotations
    Code = "flow interactive : String / {FileIO, Console, Network}",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {flow_decl, interactive,
                {type_effect,
                    {type_con, 'String', _},
                    ['FileIO', 'Console', 'Network'],
                _},
            [], _}
        ], _},
        AST
    ).

%%====================================================================
%% Integration Tests
%%====================================================================

integration_effect_complete_program_test() ->
    %% Test complete program with effect declaration, perform, and try-with
    Code = "effect FileIO\n"
           "  operation readFile : String\n"
           "end\n"
           "\n"
           "flow loadConfig =\n"
           "  perform FileIO.readFile()\n"
           "\n"
           "flow main =\n"
           "  try\n"
           "    loadConfig\n"
           "  with FileIO {\n"
           "    readFile -> 0\n"
           "  }\n"
           "  end",
    Tokens = tokenize_source(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    ?assertMatch(
        {module, undefined, [], [], [
            {effect_decl, 'FileIO', [
                {effect_operation, readFile, {type_con, 'String', _}, _}
            ], _},
            {flow_decl, loadConfig, undefined, [
                {flow_clause, [], undefined,
                    {perform_expr, 'FileIO', readFile, [], _},
                _}
            ], _},
            {flow_decl, main, undefined, [
                {flow_clause, [], undefined,
                    {try_with_expr,
                        {var, loadConfig, _},
                        [
                            {handler_clause, 'FileIO', [
                                {operation_case, readFile, [],
                                    {literal, 0, integer, _},
                                _}
                            ], _}
                        ],
                    _},
                _}
            ], _}
        ], _},
        AST
    ).

%%====================================================================
%% Error Recovery Tests
%%====================================================================
%%
%% Comprehensive error recovery testing for effect syntax.
%% Tests parser's ability to detect malformed syntax and provide
%% helpful error messages without crashing or hanging.
%%
%% Categories:
%%   1. Effect Declaration Errors
%%   2. Perform Expression Errors  
%%   3. Try-With Handler Errors
%%   4. Effect Annotation Errors
%%   5. Syntax Completion Errors
%%   6. Type Expression Errors
%%

%% Test missing 'end' keyword in effect declaration
error_effect_missing_end_test() ->
    Code = "effect Broken\n"
           "  operation test : String",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test missing operation name in effect declaration
error_effect_missing_operation_name_test() ->
    Code = "effect BadEffect\n"
           "  operation : String\n"
           "end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test missing effect name in perform expression
error_perform_missing_effect_name_test() ->
    Code = "flow bad = perform op()",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test incomplete handler - missing operation case
error_handler_missing_operation_case_test() ->
    Code = "flow bad =\n"
           "  try\n"
           "    42\n"
           "  with Effect {\n"
           "  }\n"
           "  end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test malformed type annotation
error_malformed_type_annotation_test() ->
    %% Changed from empty effect set (which should be supported) toçœŸæ­£ malformed case
    Code = "flow bad : String / {  , }",  % Empty element with comma - truly malformed
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test empty effect annotation should be SUPPORTED (not an error)
effect_annotation_empty_supported_test() ->
    %% Documentation test: empty effect annotations should be supported
    %% This test will demonstrate the issue and its resolution
    Code = "flow pureFunc : String / {}",
    Result = parse_and_expect_error(Code),
    ?assertMatch({error, _}, Result),  % Currently fails - this is the gap to fix
    io:format("Issue confirmed: Empty effect annotations not supported: ~p~n", [Result]).

%% Test missing 'with' clause in try-with
error_try_with_missing_with_test() ->
    Code = "flow bad =\n"
           "  try\n"
           "    perform Effect.op()\n"
           "  end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test malformed perform expression - missing required parentheses
error_perform_missing_parentheses_test() ->
    Code = "flow bad = perform Effect.op",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%%====================================================================
%% Additional Effect Declaration Error Tests
%%====================================================================

%% Test effect with missing effect name
error_effect_missing_name_test() ->
    Code = "effect \n"
           "  operation test : String\n"
           "end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test effect with missing operation keyword
error_effect_missing_operation_keyword_test() ->
    Code = "effect TestEffect\n"
           "  test : String\n"
           "end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test effect with malformed type annotation
error_effect_malformed_type_test() ->
    Code = "effect BadEffect\n"
           "  operation test : \n"
           "end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test effect with invalid token colon after operation
error_effect_invalid_token_after_operation_test() ->
    Code = "effect BadEffect\n"
           "  operation test : String :\n"
           "end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%%====================================================================
%% Additional Perform Expression Error Tests
%%====================================================================

%% Test perform with missing operation name
error_perform_missing_operation_name_test() ->
    Code = "flow bad = perform Effect.()",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test perform with missing dot separator
error_perform_missing_dot_test() ->
    Code = "flow bad = perform Effect op()",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test perform with invalid arguments
error_perform_invalid_args_test() ->
    Code = "flow bad = perform Effect.op(arg1, , arg3)",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test perform with mismatched parentheses
error_perform_mismatched_parens_test() ->
    Code = "flow bad = perform Effect.op(arg1",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%%====================================================================
%% Additional Try-With Handler Error Tests
%%====================================================================

%% Test try-with with missing opening brace in handler
error_handler_missing_opening_brace_test() ->
    Code = "flow bad =\n"
           "  try\n"
           "    perform Effect.op()\n"
           "  with Effect\n"
           "    op\n"
           "  end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test try-with with missing closing brace in handler
error_handler_missing_closing_brace_test() ->
    Code = "flow bad =\n"
           "  try\n"
           "    perform Effect.op()\n"
           "  with Effect {\n"
           "    op -> 42\n"
           "  end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test handler with malformed operation case
error_handler_malformed_operation_case_test() ->
    Code = "flow bad =\n"
           "  try\n"
           "    perform Effect.op()\n"
           "  with Effect {\n"
           "    -> 42\n"
           "  }\n"
           "  end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test handler with missing arrow in operation case
error_handler_missing_arrow_test() ->
    Code = "flow bad =\n"
           "  try\n"
           "    perform Effect.op()\n"
           "  with Effect {\n"
           "    op 42\n"
           "  }\n"
           "  end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%%====================================================================
%% Additional Effect Annotation Error Tests
%%====================================================================

%% Test effect annotation with malformed effect list
error_effect_annotation_malformed_list_test() ->
    Code = "flow bad : String / {Effect1 Effect2}",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test effect annotation with missing opening brace
error_effect_annotation_missing_opening_brace_test() ->
    Code = "flow bad : String / Effect1, Effect2}",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test effect annotation with missing closing brace
error_effect_annotation_missing_closing_brace_test() ->
    Code = "flow bad : String / {Effect1, Effect2",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test effect annotation with invalid effect name
error_effect_annotation_invalid_effect_test() ->
    Code = "flow bad : String / {123Invalid}",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%%====================================================================
%% Syntax Completion and Edge Case Error Tests
%%====================================================================

%% Test incomplete effect declaration
error_incomplete_effect_declaration_test() ->
    Code = "effect",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test incomplete perform expression
error_incomplete_perform_expression_test() ->
    Code = "flow bad = perform",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test incomplete try-with statement
error_incomplete_try_with_test() ->
    Code = "flow bad = try",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%% Test handler with invalid operation parameters
error_handler_invalid_params_test() ->
    Code = "flow bad =\n"
           "  try\n"
           "    perform Effect.op()\n"
           "  with Effect {\n"
           "    op(123Invalid) -> 42\n"
           "  }\n"
           "  end",
    Result = parse_and_expect_error(Code),
    assert_error_has_location(Result).

%%====================================================================
%% Security and Stress Tests
%%====================================================================
%%
%% Security testing for effect syntax implementation.
%% Tests various attack vectors, boundary conditions, and edge cases.
%%
%% Categories:
%%   1. Boundary Conditions (tests at maximum limits)
%%   2. Malicious Input Tests (unicode, special chars, injection)
%%   3. Resource Exhaustion Attempts (large constructs, deep nesting)
%%   4. Parser Attack Patterns (ambiguity, confusion)
%%   5. Memory Safety Tests (large strings, tokens)
%%   6. DoS Protection Tests (algorithmic complexity attacks)
%%   7. ERROR SECURITY TESTS (malformed + attack patterns)
%%

%% Test effect with long identifier length
security_max_identifier_length_test() ->
    %% Create 50-character effect name (well within limits) using uppercase letter
    LongName = string:copies("A", 50),
    Code = "effect " ++ LongName ++ "\n"
           "  operation test\n"
           "end",
    {ok, Tokens} = topos_lexer:tokenize(Code),
    {ok, AST} = topos_parser:parse(Tokens),
    %% Convert string to atom for pattern match
    LongNameAtom = list_to_atom(LongName),
    ?assertMatch(
        {module, undefined, [], [], [
            {effect_decl, LongNameAtom, [
                {effect_operation, test, undefined, _}
            ], _}
        ], _},
        AST
    ).

%% Test deeply nested try-with expressions (testing recursion limits)
security_deeply_nested_try_with_test() ->
    %% Create deeply nested try-with to test parser limits
    NestingLevel = 50,
    BaseExpr = "perform Effect.op()",
    NestedExpr = create_nested_try_with(NestingLevel, BaseExpr),
    Code = "flow nestedTest = " ++ NestedExpr,
    %% This should either parse successfully or hit parser limits gracefully
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Successfully parsed within limits
                {error, _Reason} ->
                    ?assert(true)   % Hit limits gracefully
            end;
        {error, _LexError} ->
            ?assert(true)       % Hit lexer limits
    end.

%% Test effect with many operations (testing parser performance)
security_many_operations_test() ->
    %% Create effect with 100 operations to test parser limits
    OperationCount = 100,
    Operations = [lists:flatten(io_lib:format("  operation op~p : String~n", [I])) || I <- lists:seq(1, OperationCount)],
    Code = "effect LargeEffect\n" ++ string:join(Operations, "") ++ "end",
    %% This should either parse successfully or hit parser limits gracefully
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Successfully parsed within limits
                {error, _Reason} ->
                    ?assert(true)   % Hit limits gracefully
            end;
        {error, _LexError} ->
            ?assert(true)       % Hit lexer limits
    end.

%% Test try-with with many handlers
security_many_handlers_test() ->
    %% Create try-with with 20 different handlers
    HandlerCount = 20,
    Handlers = [lists:flatten(io_lib:format("  Effect~p { op~p -> ~p }", [I, I, I])) || I <- lists:seq(1, HandlerCount)],
    HandlerCode = string:join(Handlers, "\n"),
    Code = "flow manyHandlers =\n"
           "  try\n"
           "    perform Effect1.op1()\n"
           "  with\n"
           "  " ++ HandlerCode ++ "\n"
           "  end",
    %% This should either parse successfully or hit parser limits gracefully
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Successfully parsed within limits
                {error, _Reason} ->
                    ?assert(true)   % Hit limits gracefully
            end;
        {error, _LexError} ->
            ?assert(true)       % Hit lexer limits
    end.

%% Test complex effect annotation with many effects
security_many_effects_test() ->
    %% Create type annotation with 20 effects
    EffectCount = 20,
    Effects = [lists:flatten(io_lib:format("Effect~p", [I])) || I <- lists:seq(1, EffectCount)],
    EffectList = string:join(Effects, ", "),
    Code = "flow manyEffects : String / {" ++ EffectList ++ "}",
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Successfully parsed within limits
                {error, _Reason} ->
                    ?assert(true)   % Hit limits gracefully
            end;
        {error, _LexError} ->
            ?assert(true)       % Hit lexer limits
    end.

%%====================================================================
%% Boundary Condition Tests
%%====================================================================

%% Test maximum identifier length (255 chars)
security_max_identifier_boundary_test() ->
    %% Test exactly at the 255 character limit
    MaxLongName = string:copies("A", 255),
    Code = "effect " ++ MaxLongName ++ "\n"
           "  operation test\n"
           "end",
    %% Should either parse successfully or fail gracefully at boundary
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Successfully parsed at boundary
                {error, _Reason} ->
                    ?assert(true)   % Failed gracefully at boundary
            end;
        {error, _LexError} ->
            ?assert(true)       % Failed at lexer boundary
    end.

%% Test identifier length exceeding maximum
security_oversized_identifier_test() ->
    %% Test exceeding the 255 character limit
    TooLongName = string:copies("A", 256),
    Code = "effect " ++ TooLongName ++ "\n"
           "  operation test\n"
           "end",
    %% Should fail at lexer level (security feature)
    case topos_lexer:tokenize(Code) of
        {ok, _Tokens} ->
            %% This should NOT happen - lexer should reject oversized identifiers
            ?assert(false, "Lexer incorrectly accepted oversized identifier");
        {error, _LexError} ->
            ?assert(true)       % Correctly rejected by lexer (good security)
    end.

%%====================================================================
%% Malicious Input Tests
%%====================================================================

%% Test Unicode characters in effect names
security_unicode_effect_name_test() ->
    %% Test with Unicode characters that might cause issues
    UnicodeName = "Effect_ð”˜ð”«ð”¦ð” ð”¬ð”¡ð”¢_ðŸŽ­_Ñ„Ð°Ð¹Ð»",
    Code = "effect " ++ UnicodeName ++ "\n"
           "  operation test\n"
           "end",
    %% Should handle Unicode safely (reject for security - lexer doesn't allow Unicode)
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            %% If lexer accepts Unicode, parser should handle it
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Safely parsed Unicode
                {error, _Reason} ->
                    ?assert(true)   % Safely rejected Unicode
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected by lexer (preferable for security)
    end.

%% Test control characters and special sequences
security_control_characters_test() ->
    %% Test with potentially dangerous control characters
    MaliciousEffect = "Effect" ++ [0, 1, 2, 3, 4, 5] ++ "Test",
    MaliciousOperation = "op" ++ [127, 255, 254],
    Code = "effect " ++ MaliciousEffect ++ "\n"
           "  operation " ++ MaliciousOperation ++ "\n"
           "end",
    %% Should be rejected at lexer level (security feature)
    case topos_lexer:tokenize(Code) of
        {ok, _Tokens} ->
            %% This should NOT happen - lexer should reject control characters
            ?assert(false, "Lexer incorrectly accepted control characters");
        {error, _LexError} ->
            ?assert(true)       % Safely rejected by lexer (good security)
    end.

%% Test ANSI escape sequence injection attempt
security_ansi_injection_test() ->
    %% Test for ANSI escape sequence injection
    MaliciousEffect = "Normal" ++ "\033[31m" ++ "RedText" ++ "\033[0m",
    Code = "effect " ++ MaliciousEffect ++ "\n"
           "  operation test\n"
           "end",
    %% Should be rejected at lexer level (security feature)
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            %% If lexer accepts ANSI, parser should handle it safely
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Sanitized and parsed
                {error, _Reason} ->
                    ?assert(true)   % Rejected for safety
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected by lexer (preferable for security)
    end.

%%====================================================================
%% Resource Exhaustion Tests
%%====================================================================

%% Test extremely large string literal
security_large_string_test() ->
    %% Create effect with very large string literal
    LargeString = string:copies("X", 10000),
    Code = "effect StringEffect\n"
           "  operation test : String\n"
           "  operation largeTest = \"" ++ LargeString ++ "\"\n"
           "end",
    %% Should handle large strings without memory issues
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Handled large string safely
                {error, _Reason} ->
                    ?assert(true)   % Rejected for size limits
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected
    end.

%% Test deep operation parameter nesting
security_deep_parameter_nesting_test() ->
    %% Create deeply nested operation parameters
    ParamCount = 100,
    Params = ["p" ++ integer_to_list(I) || I <- lists:seq(1, ParamCount)],
    ParamList = string:join(Params, ", "),
    Code = "effect DeepEffect\n"
           "  operation deep(" ++ ParamList ++ ") : Unit\n"
           "end",
    %% Should handle large parameter lists within limits
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Handled within limits
                {error, _Reason} ->
                    ?assert(true)   % Rejected for limit violation
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected
    end.

%%====================================================================
%% Parser Attack Pattern Tests
%%====================================================================

%% Test ambiguous perform expression syntax
security_perform_ambiguity_test() ->
    %% Test perform expressions that might confuse the parser
    Code = "flow test = perform A.B.C.D.E.F()",
    %% Should either parse clearly or reject unambiguously
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Parsed clearly
                {error, _Reason} ->
                    ?assert(true)   % Rejected unambiguously
            end;
        {error, _LexError} ->
            ?assert(true)       % Lexically invalid
    end.

%% Test malformed effect set syntax
security_malformed_effect_set_test() ->
    %% Test various malformed effect set syntaxes
    MalformedSets = [
        "flow bad : Int / {  , Effect }",      % Empty element in set
        "flow bad2 : Int / { Effect, }",      % Trailing comma
        "flow bad3 : Int / {Effect Effect}",  % Missing comma
        "flow bad4 : Int / {{Effect}}",       % Double braces
        "flow bad5 : Int / {}Effect"          % Missing separator
    ],
    %% All should be rejected cleanly
    lists:foreach(fun(TestCode) ->
        Result = parse_and_expect_error(TestCode),
        ?assertMatch({error, _}, Result)
    end, MalformedSets).

%%====================================================================
%% Memory Safety Tests
%%====================================================================

%% Test large number of perform expressions
security_many_perform_expressions_test() ->
    %% Create flow with many perform expressions
    PerformCount = 50,
    Performs = [lists:flatten(io_lib:format("  perform Effect~p.op~p()", [I, I])) || I <- lists:seq(1, PerformCount)],
    PerformCode = "flow manyPerforms =\n" ++ string:join(Performs, "\n"),
    %% Should handle many performs within memory limits
    case topos_lexer:tokenize(PerformCode) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Handled within limits
                {error, _Reason} ->
                    ?assert(true)   % Rejected for limits
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected
    end.

%% Test complex nested handlers
security_complex_nested_handlers_test() ->
    %% Create complex nested try-with structures
    Code = "flow complex =\n"
           "  try\n"
           "    try\n"
           "      perform Effect1.op()\n"
           "    with Effect1 {\n"
           "      op -> perform Effect2.op()\n"
           "    } with Effect2 {\n"
           "      op -> 42\n"
           "    } end\n"
           "  with Effect3 {\n"
           "      op -> 0\n"
           "  } end",
    %% Should handle complex nesting without infinite recursion
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Handled complex structure
                {error, _Reason} ->
                    ?assert(true)   % Rejected for complexity limits
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected
    end.

%%====================================================================
%% DoS Protection Tests
%%====================================================================

%% Test exponential complexity attempt
security_exponential_complexity_test() ->
    %% Create potentially exponentially complex effect annotation
    %% This attempts to create many combinations of effects
    BaseEffects = ["E" ++ integer_to_list(I) || I <- lists:seq(1, 10)],
    %% Create combinations to test parser limits
    ComplexEffects = string:join(BaseEffects, ", "),
    Code = "flow complexAnnotated : Int / {" ++ ComplexEffects ++ "}",
    %% Should handle within complexity limits or reject gracefully
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Handled within limits
                {error, _Reason} ->
                    ?assert(true)   % Rejected for complexity protection
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected
    end.

%% Test token flood attempt
security_token_flood_test() ->
    %% Create source with many tokens (reduced to be reasonable)
    FloodCount = 50,
    SimpleTokens = ["Effect" ++ integer_to_list(I) || I <- lists:seq(1, FloodCount)],
    EffectList = string:join(SimpleTokens, ", "),
    Code = "flow tokenFlood : Int / {" ++ EffectList ++ "}",
    %% Should handle token flood safely within limits
    case topos_lexer:tokenize(Code) of
        {ok, LexTokens} ->
            case topos_parser:parse(LexTokens) of
                {ok, _AST} ->
                    ?assert(true);  % Handled token flood safely
                {error, _Reason} ->
                    ?assert(true)   % Rejected for token count limits
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected by lexer limits
    end.

%% Test pathological nesting depth
security_pathological_nesting_test() ->
    %% Create deeply nested perform expressions to test stack depth limits
    NestingDepth = 50,
    %% Create nested pattern like: perform E1.op1() where perform E2.op2() where ...
    NestedPerforms = [lists:flatten(io_lib:format("perform E~p.op~p()", [I, I])) || I <- lists:seq(1, NestingDepth)],
    NestedExpr = string:join(NestedPerforms, " where "),
    Code = "flow deepTest = " ++ NestedExpr,
    %% Should either handle within depth limits or reject gracefully
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Handled within depth limits
                {error, _Reason} ->
                    ?assert(true)   % Rejected for depth protection
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected
    end.

%%====================================================================
%% Error Security Tests
%%====================================================================
%%
%% Tests combining malformed syntax with security concerns.
%% Ensures parser remains stable and secure under malformed attack patterns.

%% Test malformed effect with maximum identifier length
error_security_max_length_malformed_test() ->
    %% Combine boundary violation with malformed syntax
    LongName = string:copies("A", 255),
    MalformedCode = "effect " ++ LongName ++ "\n"
                    "  operation : Missing colon and type\n"
                    "  operation test :: Double colon\n"
                    "end",
    %% Should handle gracefully without exposing vulnerabilities
    case topos_lexer:tokenize(MalformedCode) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(false, "Parser incorrectly accepted malformed syntax");
                {error, _Reason} ->
                    ?assert(true)   % Correctly rejected malformed syntax
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected at lexer level
    end.

%% Test malformed syntax with control characters
error_security_control_chars_malformed_test() ->
    %% Combine control characters with malformed syntax for combined attack
    MaliciousCode = "effect Effect" ++ [0, 1, 2, 3] ++ "Test\n"
                   "  operation \n\t" ++ [127, 255] ++ " : \n\r\n"
                   "  operation test () -> Missing colon\n"
                   "end",
    %% Should reject without crashing or hanging
    case topos_lexer:tokenize(MaliciousCode) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(false, "Parser incorrectly accepted control character malformed code");
                {error, _Reason} ->
                    ?assert(true)   % Correctly rejected
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected by lexer (preferred)
    end.

%% Test malformed nested try-with with depth attack
error_security_nested_malformed_test() ->
    %% Create malformed nested syntax with excessive depth
    NestDepth = 20,
    %% Create malformed nested pattern
    MalformedInner = string:join(
        [lists:flatten(io_lib:format(" try " ++ string:copies("{ ", I) ++ " perform~p() end", [I])) 
         || I <- lists:seq(1, NestDepth)], " "),
    Code = "flow malformedNested = " ++ MalformedInner,
    %% Should handle resource exhaustion attempt within malformed syntax
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(true);  % Handled within limits (preferable)
                {error, _Reason} ->
                    ?assert(true)   % Rejected for protection (acceptable)
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected by lexer
    end.

%% Test malformed effect annotations with token flood
error_security_malformed_token_flood_test() ->
    %% Combine malformed syntax with token flood attempt
    %% Mix valid and malformed tokens to confuse parser
    MixTokens = ["Effect" ++ integer_to_list(I) || I <- lists:seq(1, 10)],
    MalformedTokens = ["123Invalid", "", " ", ":::", "{{{", "}}}"],
    AllTokens = MixTokens ++ MalformedTokens,
    MalformedEffectList = string:join(AllTokens, ", "),
    %% Introduce malformed effect annotation syntax
    Code = "flow malformedFlood : Int / {" ++ MalformedEffectList ++ ":::",  % Extra colon makes it malformed
    %% Should handle malformed flood safely
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(false, "Parser incorrectly accepted malformed effect annotation");
                {error, _Reason} ->
                    ?assert(true)   % Correctly rejected malformed syntax
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected by lexer
    end.

%% Test malformed perform expressions with Unicode + control chars
error_security_perform_unicode_control_test() ->
    %% Combine unicode, control characters, and malformed perform syntax
    MalformedPerform = "perform Effect" ++ [0, 255] ++ "." ++ "ð”˜ð”«ð”¦ð” ð”¬ð”¡ð”¢" ++ "(, ,",  % Malformed args with unicode and controls
    Code = "flow unicodeControlMalformed = " ++ MalformedPerform,
    %% Should reject combination attack safely
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(false, "Parser incorrectly accepted unicode + control char malformed perform");
                {error, _Reason} ->
                    ?assert(true)   % Correctly rejected
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected by lexer
    end.

%% Test malformed handlers with memory stress
error_security_handler_memory_stress_test() ->
    %% Create handlers with many malformed operation cases to test memory limits
    MalformedHandlersNum = 50,
    MalformedCases = lists:duplicate(MalformedHandlersNum, "  -> 42"),  % Missing operation name
    HandlerBody = string:join(MalformedCases, "\n"),
    Code = "flow memoryStressMalformed =\n"
           "  try\n"
           "    perform Effect.op()\n"
           "  with Effect {\n"
           ++ HandlerBody ++ "\n"
           "  }\n"
           "  end",
    %% Should handle memory stress with malformed syntax
    case topos_lexer:tokenize(Code) of
        {ok, Tokens} ->
            case topos_parser:parse(Tokens) of
                {ok, _AST} ->
                    ?assert(false, "Parser incorrectly accepted malformed handlers with memory stress");
                {error, _Reason} ->
                    ?assert(true)   % Correctly rejected malformed syntax
            end;
        {error, _LexError} ->
            ?assert(true)       % Safely rejected by lexer
    end.

%% Test parser resurrection after malformed attack
error_security_recovery_resilience_test() ->
    %% Test that parser remains functional after processing malformed attacks
    MalformedAttacks = [
        "effect ",  % Incomplete
        "perform (",  % Malformed perform
        "try { end",  % Malformed try-with
        "effect X { operation ",  % Malformed operation
        "flow bad : Int / {"  % Malformed annotation
    ],
    %% Process multiple malformed attacks in sequence
    lists:foreach(fun(MalformedCode) ->
        case topos_lexer:tokenize(MalformedCode) of
            {ok, Tokens} ->
                case topos_parser:parse(Tokens) of
                    {ok, _AST} ->
                        ?assert(false, "Parser incorrectly accepted malformed attack");
                    {error, _Reason} ->
                        ?assert(true)   % Correctly rejected
                end;
            {error, _LexError} ->
                ?assert(true)       % Safely rejected by lexer
        end
    end, MalformedAttacks),
    %% Verify parser still works with valid code after attacks
    ValidCode = "effect ValidTest\n  operation test : String\nend",
    {ok, ValidTokens} = topos_lexer:tokenize(ValidCode),
    {ok, _ValidAST} = topos_parser:parse(ValidTokens),
    ?assert(true).  % Parser resilience successful


